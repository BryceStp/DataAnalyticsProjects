---
title: 'STA 5936: Homework 2'
date: 'Due January 23rd, 11:59pm'
name: Bryce St.Pierre
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this problem we use the abalone dataset available on Canvas. The
dataset is about predicting the age of the abalone from its physical
measurements. Use the first 7 variables as predictors and the 8-th as
the response. Obtain all results using 10-fold cross-validation, which
is computed as follows:

1.  Generate a random permutation of the data. Use this random
    permutation to split the data into 10 disjoint subsets of almost
    equal size (417 or 418 observations each).

2.  For each fold i ∈ {1, ..., 10}, train the model on all data except
    subset i and test it on subset i, obtaining test error εi.

3.  Obtain the final test error as the average of the 10 test errors εi
    obtained above. Here the errors εi could be the MSE, or the R2.
    Report results for the following models:

    a)  Null model. Report the average train and test MSE of the null
        model that always predicts training ̄y (average training y). (1
        point)

        -   

    b)  OLS regression computed analytically by solving the following
        normal equations: (1 N XT X + λIp)β = 1 N XT Y where λ ∈ {0,
        10−5, 10−4, 10−3, 10−2, 10−1} and N is the number of observa-
        tions in X. Report in a table the average training and test R2
        and MSE, as well as their standard deviations obtained from the
        10 folds. On the same graph, plot the average average training
        and test MSE vs λ as two separate curves. Also plot the average
        value of the logarithm of the determinant of 1 N XT X + λIp
        (average obtained from the 10 folds) vs λ. (3 points)

        -   t

    c)  Regression tree of maximum depth 1, 2, .... up to 7, for a total
        of 7 regression trees. On the same plot, plot the average
        training and test R2 vs the tree depth as two separate curves.
        On another plot, plot the average training and test MSE vs the
        tree depth, and show the null model MSE from a) as a horizontal
        line. (2 points)

        -   t

    d)  Random forest regression with 10, 30, 100 and 300 trees. Report
        the average training, OOB, and test R2 and MSE and their
        standard deviations in each case. On the same plot, plot the
        average training, OOB and test R2 vs the number of trees as
        three separate curves. How does the average OOB R2 compare to
        the test R2? (2 points)

        -   t

```{r}
df <- read.csv("C:/Users/Bryce/Downloads/STA 5635/HW2/abalone.csv", header = FALSE, sep = ",")

```

```{r}
set.seed(0)

n <- nrow(df)
k <- 10

RandPerm <- sample(n)

# Split data
foldSize <- rep(floor(n/k), k)

foldSize[1:(n %% k)] <- foldSize[1:(n %% k)] + 1

folds <- split(RandPerm, rep(1:k, foldSize))

foldedData <- lapply(folds, function(indices) df[indices, ])

# Check folds
sapply(foldedData, nrow)
```

```{r}
library(Metrics)

# Model Training for the Null Model
trainMSE <- numeric(10)
testMSE <- numeric(10)

for (i in 1:10) {
  
  testIndices <- folds[[i]]
  trainIndices <- setdiff(1:nrow(df), testIndices)
  
  trainData <- df[trainIndices, ]
  testData <- df[testIndices, ]
  
  yTrain <- trainData$V8  
  yTest <- testData$V8   
  yTrainMean <- mean(yTrain)
  
  trainMSE[i] <- mse(yTrain, rep(yTrainMean, length(yTrain)))  
  testMSE[i] <- mse(yTest, rep(yTrainMean, length(yTest)))
}

averageTrainMSE <- mean(trainMSE)
averageTestMSE <- mean(testMSE)

cat("Average Training MSE (Null Model):", averageTrainMSE, "\n")
cat("Average Test MSE (Null Model):", averageTestMSE, "\n")
```

```{r}
library(caret)
library(Matrix)

lambdas <- c(0, 10^(-5), 10^(-4), 10^(-3), 10^(-2), 10^(-1))

trainMSE <- testMSE <- trainR2 <- testR2 <- logDet <- matrix(NA, nrow = length(lambdas), ncol = k)

# cv and fitting
for (lambdaIDX in 1:length(lambdas)) {
  lambda <- lambdas[lambdaIDX]
  
  for (foldIDX in 1:k) {
    
    testData <- foldedData[[foldIDX]]
    trainData <- do.call(rbind, foldedData[-foldIDX])
    
    xTrain <- cbind(1, as.matrix(trainData[, -ncol(df)]))
    yTrain <- trainData[, ncol(df)]
    xTest <- cbind(1, as.matrix(testData[, -ncol(df)]))
    yTest <- testData[, ncol(df)]
    
    # Normal equation
    XTX <- t(xTrain) %*% xTrain / nrow(xTrain)
    XTXlambda <- XTX + lambda * diag(ncol(xTrain))
    XTY <- t(xTrain) %*% yTrain / nrow(xTrain)
    
    beta <- solve(XTXlambda, XTY)
    
    # Train pred and perf
    yTrainPred <- xTrain %*% beta
    trainMSE[lambdaIDX, foldIDX] <- mse(yTrain, yTrainPred)
    trainR2[lambdaIDX, foldIDX] <- R2(yTrain, yTrainPred)
    
    # Test pred and perf
    yTestPred <- xTest %*% beta
    testMSE[lambdaIDX, foldIDX] <- mse(yTest, yTestPred)
    testR2[lambdaIDX, foldIDX] <- R2(yTest, yTestPred)
    
    # Log det
    logDet[lambdaIDX, foldIDX] <- determinant(XTXlambda, logarithm = TRUE)$modulus
  }
}

# avg and std dev
trainMSEavg <- apply(trainMSE, 1, mean)
testMSEavg <- apply(testMSE, 1, mean)
trainMSEsd <- apply(trainMSE, 1, sd)
testMSEsd <- apply(testMSE, 1, sd)

trainR2avg <- apply(trainR2, 1, mean)
testR2avg <- apply(testR2, 1, mean)

logDetavg <- apply(logDet, 1, mean)

results <- data.frame(
  Lambda = lambdas,
  TrainR2avg = trainR2avg,
  TestR2avg = testR2avg,
  TrainMSEavg = trainMSEavg,
  TestMSEavg = testMSEavg,
  TrainMSEsd = trainMSEsd,
  TestMSEsd = testMSEsd,
  LogDetavg = logDetavg
)

# Print results
print(results)

```

```{r}
print(lambdas)
```

```{r}
plot(lambdas, trainMSEavg, type = "b", col = "blue", xlab = "Lambda", ylab = "MSE", main = "Training and Test MSE vs Lambda")
lines(lambdas, testMSEavg, type = "b", col = "red")
legend("bottomright", legend = c("Train MSE", "Test MSE"), col = c("blue", "red"), lty = 1)
```

```{r}
plot(lambdas, logDetavg, type = "b", col = "red", xlab = "Lambda", ylab = "Log(Determinant)", main = "Log Determinant vs Lambda")
```

```{r}
library(rpart)
library(dplyr)

k <- length(foldedData) 

trainMSE <- matrix(NA, nrow = length(1:7), ncol = k)
testMSE <- matrix(NA, nrow = length(1:7), ncol = k)
trainR2 <- matrix(NA, nrow = length(1:7), ncol = k)
testR2 <- matrix(NA, nrow = length(1:7), ncol = k)


for (depth in 1:7) {
  
  for (foldIDX in 1:k) {
    
    testData <- foldedData[[foldIDX]]
    trainData <- do.call(rbind, foldedData[-foldIDX])
    
    # Tree
    tree_model <- rpart(
      V8 ~ .,  
      data = trainData,
      method = "anova",
      control = rpart.control(maxdepth = depth)
    )
    
    # Train preds
    yTrainPred <- predict(tree_model, trainData)
    yTrain <- trainData$V8
    trainMSE[depth, foldIDX] <- mse(yTrain, yTrainPred)
    trainR2[depth, foldIDX] <- R2(yTrain, yTrainPred)
    
    # Test preds
    yTestPred <- predict(tree_model, testData)
    yTest <- testData$V8
    testMSE[depth, foldIDX] <- mse(yTest, yTestPred)
    testR2[depth, foldIDX] <- R2(yTest, yTestPred)
  }
}

trainMSEavg <- apply(trainMSE, 1, mean)
testMSEavg <- apply(testMSE, 1, mean)
trainR2avg <- apply(trainR2, 1, mean)
testR2avg <- apply(testR2, 1, mean)

results <- data.frame(
  Depth = 1:7,
  TrainMSEavg = trainMSEavg,
  TestMSEavg = testMSEavg,
  TrainR2avg = trainR2avg,
  TestR2avg = testR2avg)  

print(results)
```

```{r}
plot(1:7, trainR2avg, type = "b", col = "blue", ylim = c(0, 1),
     xlab = "Tree Depth", ylab = "Average R2", main = "R2 vs Tree Depth")

lines(1:7, testR2avg, type = "b", col = "red")

legend("bottomright", legend = c("Train R2", "Test R2"), col = c("blue", "red"), lty = 1, cex = 0.8)
```

```{r}
plot(1:7, trainMSEavg, type = "b", col = "blue", pch = 16, ylim = range(c(trainMSEavg, testMSEavg, averageTestMSE)),
     xlab = "Tree Depth", ylab = "Average MSE", main = "MSE vs Tree Depth ")

lines(1:7, testMSEavg, type = "b", col = "red", pch = 16)

abline(h = averageTestMSE, col = "green", lty = 2, lwd = 2)

legend("center", legend = c("Train MSE", "Test MSE", "Null Model MSE"),
       col = c("blue", "red", "green"), lty = c(1, 1, 2), pch = c(16, 16, NA), lwd = c(1, 1, 2), cex = 0.8)

```

```{r}
library(randomForest)

treeCount <- c(10, 30, 100, 300)
trainR2 <- testR2 <- oobR2 <- trainMSE <- testMSE <- oobMSE <- matrix(NA, nrow = length(treeCount), ncol = k)

for (nTrees in treeCount) {
  for (i in 1:k) {
    
    testIndices <- folds[[i]]
    trainIndices <- setdiff(1:nrow(df), testIndices)
    
    trainData <- df[trainIndices, ]
    testData <- df[testIndices, ]
    
    rfModel <- randomForest(V8 ~ ., data = trainData, ntree = nTrees)
    
    # Train preds
    yTrainPred <- predict(rfModel, newdata = trainData)
    trainR2[nTrees == treeCount, i] <- R2(trainData$V8, yTrainPred)
    trainMSE[nTrees == treeCount, i] <- mse(trainData$V8, yTrainPred)
    
    # OOB
    oobR2[nTrees == treeCount, i] <- rfModel$rsq[length(rfModel$rsq)]  
    oobMSE[nTrees == treeCount, i] <- mean((rfModel$y - rfModel$predicted)^2)  
    
    # test preds
    yTestPred <- predict(rfModel, newdata = testData)
    testR2[nTrees == treeCount, i] <- R2(testData$V8, yTestPred)
    testMSE[nTrees == treeCount, i] <- mse(testData$V8, yTestPred)
  }
}

# avg and std dev
trainR2avg <- apply(trainR2, 1, mean)
testR2avg <- apply(testR2, 1, mean)
oobR2avg <- apply(oobR2, 1, mean)

trainMSEavg <- apply(trainMSE, 1, mean)
testMSEavg <- apply(testMSE, 1, mean)
oobMSEavg <- apply(oobMSE, 1, mean)

trainR2sd <- apply(trainR2, 1, sd)
testR2sd <- apply(testR2, 1, sd)
oobR2sd <- apply(oobR2, 1, sd)

trainMSEsd <- apply(trainMSE, 1, sd)
testMSEsd <- apply(testMSE, 1, sd)
oobMSEsd <- apply(oobMSE, 1, sd)

results <- data.frame(
  Trees = treeCount,
  TrainR2avg = trainR2avg,
  OOBR2avg = oobR2avg,
  TestR2avg = testR2avg,
  TrainMSEavg = trainMSEavg,
  OOBMSEavg = oobMSEavg,
  TestMSEavg = testMSEavg,
  TrainR2sd = trainR2sd,
  OOBR2sd = oobR2sd,
  TestR2sd = testR2sd,
  TrainMSEsd = trainMSEsd,
  OOBMSEsd = oobMSEsd,
  TestMSEsd = testMSEsd
)

print(results)
```

```{r}
plot(treeCount, trainR2avg, type = "b", col = "blue", ylim = c(0, 1), pch = 16,
     xlab = "Number of Trees", ylab = "Average R2", main = "R2 vs Number of Trees")
lines(treeCount, oobR2avg, type = "b", col = "green", pch = 16)
lines(treeCount, testR2avg, type = "b", col = "red", pch = 16)
legend("bottomright", legend = c("Train R2", "OOB R2", "Test R2"), col = c("blue", "green", "red"), lty = 1, pch = 16)
```

```{r}
ymin <- min(c(trainMSEavg, oobMSEavg, testMSEavg), na.rm = TRUE)
ymax <- max(c(trainMSEavg, oobMSEavg, testMSEavg), na.rm = TRUE)

plot(treeCount, trainMSEavg, type = "b", col = "blue", pch = 16,
     xlab = "Number of Trees", ylab = "Average MSE", main = "MSE vs Number of Trees",
     ylim = c(ymin, ymax))  
lines(treeCount, oobMSEavg, type = "b", col = "green", pch = 16)
lines(treeCount, testMSEavg, type = "b", col = "red", pch = 16)
legend("center", legend = c("Train MSE", "OOB MSE", "Test MSE"), col = c("blue", "green", "red"), lty = 1, pch = 16)
```
