---
title: 'STA 5936: Homework 2'
date: 'Due January 23rd, 11:59pm'
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this problem we use the abalone dataset available on Canvas. The
dataset is about predicting the age of the abalone from its physical
measurements. Use the first 7 variables as predictors and the 8-th as
the response. Obtain all results using 10-fold cross-validation, which
is computed as follows:

1.  Generate a random permutation of the data. Use this random
    permutation to split the data into 10 disjoint subsets of almost
    equal size (417 or 418 observations each).

2.  For each fold i ∈ {1, ..., 10}, train the model on all data except
    subset i and test it on subset i, obtaining test error εi.

3.  Obtain the final test error as the average of the 10 test errors εi
    obtained above. Here the errors εi could be the MSE, or the R2.
    Report results for the following models:

    a)  Null model. Report the average train and test MSE of the null
        model that always predicts training ̄y (average training y). (1
        point)

        -   **t**

    b)  OLS regression computed analytically by solving the following
        normal equations: (1 N XT X + λIp)β = 1 N XT Y where λ ∈ {0,
        10−5, 10−4, 10−3, 10−2, 10−1} and N is the number of observa-
        tions in X. Report in a table the average training and test R2
        and MSE, as well as their standard deviations obtained from the
        10 folds. On the same graph, plot the average average training
        and test MSE vs λ as two separate curves. Also plot the average
        value of the logarithm of the determinant of 1 N XT X + λIp
        (average obtained from the 10 folds) vs λ. (3 points)

        -   t

    c)  Regression tree of maximum depth 1, 2, .... up to 7, for a total
        of 7 regression trees. On the same plot, plot the average
        training and test R2 vs the tree depth as two separate curves.
        On another plot, plot the average training and test MSE vs the
        tree depth, and show the null model MSE from a) as a horizontal
        line. (2 points)

        -   t

    d)  Random forest regression with 10, 30, 100 and 300 trees. Report
        the average training, OOB, and test R2 and MSE and their
        standard deviations in each case. On the same plot, plot the
        average training, OOB and test R2 vs the number of trees as
        three separate curves. How does the average OOB R2 compare to
        the test R2? (2 points)

        -   t

```{python}
import pandas as pd

df = pd.read_csv('C:/Users/Bryce/Downloads/STA 5635/HW2/abalone.csv', header = None )
```

```{python}
import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score

# Assuming df is the dataset loaded as a pandas DataFrame
# Columns are assumed to be: ['feature1', 'feature2', 'feature3', ..., 'feature7', 'age']

# Split the data into predictors (X) and response (y)
X = df.iloc[:, :-1].values  # First 7 columns as predictors
y = df.iloc[:, -1].values   # 8th column as response (age)

# Initialize KFold for 10-fold cross-validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# Null Model: always predict the mean of the training set
y_train_mean = np.mean(y)

# Variables to store results
train_errors = []
test_errors = []

# Perform 10-fold cross-validation
for train_index, test_index in kf.split(X):
    # Split the data into train and test sets for this fold
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
    # Train the null model (predict the mean of the training labels)
    y_train_pred = np.full_like(y_train, y_train_mean)
    y_test_pred = np.full_like(y_test, y_train_mean)

    # Calculate train and test MSE
    train_mse = mean_squared_error(y_train, y_train_pred)
    test_mse = mean_squared_error(y_test, y_test_pred)

    # Record the errors
    train_errors.append(train_mse)
    test_errors.append(test_mse)

# Calculate the average train and test MSE
avg_train_mse = np.mean(train_errors)
avg_test_mse = np.mean(test_errors)

# Optionally, report R^2 as well
train_r2 = 1 - (np.sum(train_errors) / np.sum((y_train - np.mean(y_train))**2))
test_r2 = 1 - (np.sum(test_errors) / np.sum((y_test - np.mean(y_test))**2))

# Results
print(f"Null Model - Train MSE: {avg_train_mse:.4f}, Test MSE: {avg_test_mse:.4f}")
print(f"Null Model - Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}")

```

```{python}
import numpy as np
import pandas as pd

# Function for Mean Squared Error (MSE)
def MSE(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Function for R-squared (R2)
def R2(y_true, y_pred):
    y_mean = np.mean(y_true)
    ss_total = np.sum((y_true - y_mean) ** 2)
    ss_residual = np.sum((y_true - y_pred) ** 2)
    return 1 - (ss_residual / ss_total)

# Define lambda values
lambdas = [0, 10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1)]

# Load your dataset (assume 'df' is the DataFrame with the abalone data)
# Assuming 'df' is already loaded into the environment as per your original code.
n = len(df)
k = 10

# Shuffle the data and split into 10 folds
np.random.seed(42)
rand_perm = np.random.permutation(n)
folds = np.array_split(rand_perm, k)

# Initialize arrays for results
train_mse = np.zeros((len(lambdas), k))
test_mse = np.zeros((len(lambdas), k))
train_r2 = np.zeros((len(lambdas), k))
test_r2 = np.zeros((len(lambdas), k))
log_det = np.zeros((len(lambdas), k))

# Ridge regression and cross-validation
for lambda_idx, lambda_val in enumerate(lambdas):
    for fold_idx in range(k):
        # Split data into training and testing sets for the current fold
        test_indices = folds[fold_idx]
        train_indices = np.setdiff1d(np.arange(n), test_indices)
        
        train_data = df.iloc[train_indices]
        test_data = df.iloc[test_indices]
        
        X_train = train_data.iloc[:, :-1].values  # predictors (first 7 columns)
        y_train = train_data.iloc[:, -1].values   # response (8th column)
        X_test = test_data.iloc[:, :-1].values    # predictors (first 7 columns)
        y_test = test_data.iloc[:, -1].values     # response (8th column)
        
        # Ridge regression normal equation
        XTX = np.dot(X_train.T, X_train) / len(X_train)
        XTX_lambda = XTX + lambda_val * np.eye(X_train.shape[1])  # Regularization term
        XTY = np.dot(X_train.T, y_train) / len(X_train)
        
        # Solve for beta (ridge coefficients)
        beta = np.linalg.solve(XTX_lambda, XTY)
        
        # Training predictions and performance
        y_train_pred = np.dot(X_train, beta)
        train_mse[lambda_idx, fold_idx] = MSE(y_train, y_train_pred)
        train_r2[lambda_idx, fold_idx] = R2(y_train, y_train_pred)
        
        # Testing predictions and performance
        y_test_pred = np.dot(X_test, beta)
        test_mse[lambda_idx, fold_idx] = MSE(y_test, y_test_pred)
        test_r2[lambda_idx, fold_idx] = R2(y_test, y_test_pred)
        
        # Log determinant of XTX + lambda * I
        log_det[lambda_idx, fold_idx] = np.log(np.linalg.det(XTX_lambda))

# Compute averages and standard deviations across folds
train_mse_avg = np.mean(train_mse, axis=1)
test_mse_avg = np.mean(test_mse, axis=1)
train_mse_std = np.std(train_mse, axis=1)
test_mse_std = np.std(test_mse, axis=1)

train_r2_avg = np.mean(train_r2, axis=1)
test_r2_avg = np.mean(test_r2, axis=1)

log_det_avg = np.mean(log_det, axis=1)

# Results as a DataFrame
results = pd.DataFrame({
    'Lambda': lambdas,
    'TrainR2avg': train_r2_avg,
    'TestR2avg': test_r2_avg,
    'TrainMSEavg': train_mse_avg,
    'TestMSEavg': test_mse_avg,
    'TrainMSEsd': train_mse_std,
    'TestMSEsd': test_mse_std,
    'LogDetavg': log_det_avg
})

# Print results table
print(results)

# For plotting: Average training and test MSE vs lambda
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

# Plot average MSE vs lambda for training and testing
plt.plot(lambdas, train_mse_avg, label='Average Train MSE', marker='o')
plt.plot(lambdas, test_mse_avg, label='Average Test MSE', marker='o')

# Plot Log determinant average
plt.twinx()  # To plot on the second y-axis
plt.plot(lambdas, log_det_avg, label='Log Det(XTX + λI)', color='green', marker='x')

# Add labels and legend
plt.xlabel('Lambda')
plt.ylabel('MSE')
plt.title('Average Training and Test MSE vs Lambda')
plt.legend(loc='upper left')

# Show the plot
plt.show()

```
